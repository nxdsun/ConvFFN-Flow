import sys
sys.path.append('core')  # å°†'core'ç›®å½•æ·»åŠ åˆ°ç³»ç»Ÿè·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥æ¨¡å—
import matplotlib.pyplot as plt
from matplotlib import cm
import argparse  # ç”¨äºå‘½ä»¤è¡Œå‚æ•°è§£æ
import os  # ç”¨äºæ“ä½œç³»ç»Ÿç›¸å…³åŠŸèƒ½
import numpy as np  # NumPyåº“ï¼Œç”¨äºæ•°ç»„æ“ä½œ
import torch  # PyTorchåº“ï¼Œç”¨äºæ·±åº¦å­¦ä¹ 
from PIL import Image  # ç”¨äºåŠ è½½å’Œå¤„ç†å›¾åƒ
#from core.raft import RAFT  # å¯¼å…¥RAFTæ¨¡å‹
#from core.raft_convext import RAFT  # å¯¼å…¥RAFTæ¨¡å‹
from core.raft import RAFT
from core.utils.utils import InputPadder  # å¯¼å…¥ç”¨äºè¾“å…¥æ•°æ®å¡«å……çš„å·¥å…·ç±»
import struct
import glob
DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'
def read_flow(filename):
    """è¯»å–.floæ ¼å¼å…‰æµæ–‡ä»¶"""
    with open(filename, 'rb') as f:
        magic = struct.unpack('f', f.read(4))[0]
        if magic != 202021.25:
            raise Exception('Invalid .flo file')
        w = struct.unpack('i', f.read(4))[0]
        h = struct.unpack('i', f.read(4))[0]
        data = np.frombuffer(f.read(w * h * 8), dtype=np.float32)
        flow = np.resize(data, (h, w, 2))
    return flow
def load_image(imfile):
    # åŠ è½½å›¾åƒå¹¶è½¬æ¢ä¸ºNumPyæ•°ç»„ï¼Œåƒç´ å€¼ç±»å‹ä¸ºuint8
    img = np.array(Image.open(imfile)).astype(np.uint8)
    # æ£€æŸ¥å›¾åƒç»´åº¦ï¼šå¦‚æœæ˜¯ç°åº¦å›¾ï¼ˆH, Wï¼‰ï¼Œæ‰©å±•ä¸ºä¼ªå½©è‰²ï¼ˆH, W, 3ï¼‰
    if img.ndim == 2:  # ç°åº¦å›¾
        img = np.stack([img] * 3, axis=-1)  # è½¬æ¢ä¸ºä¼ªå½©è‰²
    # è½¬æ¢ä¸ºPyTorchå¼ é‡ï¼Œå¹¶è°ƒæ•´ç»´åº¦é¡ºåºä¸º(C, H, W)ï¼ŒåŒæ—¶å°†åƒç´ å€¼è½¬æ¢ä¸ºæµ®ç‚¹å‹
    img = torch.from_numpy(img).permute(2, 0, 1).float()
    # å°†å›¾åƒæ·»åŠ batchç»´åº¦å¹¶ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡ä¸Š

    return img[None].to(DEVICE)
def save_flow(filename, flow):
    """
    ä¿å­˜å…‰æµæ•°æ®ä¸º.floæ ¼å¼æ–‡ä»¶
    å‚æ•°:
    filename: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    flow: å…‰æµæ•°æ®ï¼Œå½¢çŠ¶ä¸º (1, 2, H, W)ï¼Œå­˜å‚¨äº†å…‰æµçš„ (u, v) åˆ†é‡
    """
    # è°ƒæ•´ç»´åº¦é¡ºåºä¸º (H, W, 2)
    flow = flow.squeeze(0).transpose((1, 2, 0))
    h, w = flow.shape[:2]

    with open(filename, 'wb') as f:
        # å†™å…¥é­”æœ¯æ•°å­—ï¼Œä½¿ç”¨ç³»ç»Ÿé»˜è®¤å­—èŠ‚åº
        f.write(struct.pack('f', 202021.25))
        # å†™å…¥å®½åº¦ï¼Œä½¿ç”¨ç³»ç»Ÿé»˜è®¤å­—èŠ‚åº
        f.write(struct.pack('i', w))
        # å†™å…¥é«˜åº¦ï¼Œä½¿ç”¨ç³»ç»Ÿé»˜è®¤å­—èŠ‚åº
        f.write(struct.pack('i', h))
        # ç¡®ä¿æ•°æ®æ˜¯ np.float32 ç±»å‹ï¼Œå±•å¹³å¹¶ç¡®ä¿å†…å­˜è¿ç»­æ€§
        flow = np.ascontiguousarray(flow.astype(np.float32)).flatten()
        f.write(flow.tobytes())
def viz(img, flo,output_path,step=15):
    # è°ƒæ•´å›¾åƒçš„ç»´åº¦é¡ºåºï¼Œä»(C, H, W)å˜ä¸º(H, W, C)ï¼Œå¹¶è½¬æ¢ä¸ºNumPyæ•°ç»„
    img = img[0].permute(1, 2, 0).cpu().numpy()
    # åŒæ ·å¤„ç†å…‰æµæ•°æ®
    flo = flo[0].permute(1, 2, 0).cpu().numpy()

    # è®¡ç®—å…‰æµçš„å¹…å€¼ï¼ˆmagnitudeï¼‰
    u = flo[:, :, 0]
    v = flo[:, :, 1]
    magnitude = np.sqrt(u**2 + v**2)
    h, w = magnitude.shape
    x, y = np.meshgrid(np.arange(0, w, step), np.arange(0, h, step))

    u_sampled = u[::step, ::step]
    v_sampled = v[::step, ::step]
    # è‡ªåŠ¨è®¡ç®—é¢œè‰²æ¡çš„æœ€å¤§æœ€å°å€¼
    # vmin = np.min(velocity)
    # vmax = np.max(velocity)
    vmin_pix = np.min(magnitude)
    vmax_pix = np.max(magnitude)
    plt.figure()
    # im = plt.imshow(magnitude, cmap='jet',vmin=vmin, vmax=5)
    im = plt.imshow(magnitude, cmap='jet', vmin=2, vmax=vmax_pix)
    plt.quiver(x, y, u_sampled, v_sampled, angles='xy', scale_units='xy', scale=0.5, color='white')
    cbar = plt.colorbar(im, shrink=0.6)
    # cbar.set_label('Water Flow Velocity (m/s)')
    cbar.set_label('Optical Flow Magnitude(pix/frame)')
    # éšè—åæ ‡è½´çš„åˆ»åº¦
    plt.xticks([])  # éšè—xè½´åˆ»åº¦
    plt.yticks([])  # éšè—yè½´åˆ»åº¦
    plt.title("COVNEXT")
    plt.savefig(output_path, bbox_inches='tight', dpi=300)  # è¿™ä¸ªæ˜¯ä¿å­˜å›¾ç‰‡
    #plt.show()
    plt.close(1)

from mpl_toolkits.axes_grid1 import make_axes_locatable
def save_error_heatmap(flow_pred, flow_gt, save_path, max_val=2.0):
    # è®¡ç®—è¯¯å·®å›¾
    error = np.sqrt(np.sum((flow_pred - flow_gt) ** 2, axis=2))

    # åˆ›å»ºå›¾åƒ
    fig, ax = plt.subplots(figsize=(8, 6))
    im = ax.imshow(error, cmap='copper', vmin=0)
    ax.axis('off')
    ax.set_title('Optical Flow Error Heatmap')

    # åˆ›å»ºç­‰é«˜çš„é¢œè‰²æ¡
    divider = make_axes_locatable(ax)
    cax = divider.append_axes("right", size="5%", pad=0.05)
    cbar = fig.colorbar(im, cax=cax)
    cbar.set_label(f'Flow Error (clipped at {max_val} pixels)')

    # ä¿å­˜çƒ­åŠ›å›¾
    plt.savefig(save_path, bbox_inches='tight', dpi=300)
    plt.close()

    # ä¿å­˜è¯¯å·®çŸ©é˜µä¸º .npy æ–‡ä»¶ï¼ˆä¸çƒ­åŠ›å›¾åç§°ä¸€è‡´ï¼‰
    npy_path = os.path.splitext(save_path)[0] + '.npy'
    np.save(npy_path, error)


def get_image_pairs(path):
    # æ‰¾åˆ°æ‰€æœ‰ä»¥ _a. ç»“å°¾çš„æ–‡ä»¶
    images_a = sorted(glob.glob(os.path.join(path, '*_a.jpg')))
    pairs = []
    for im_a in images_a:
        im_b = im_a.replace('_a.', '_b.')
        if os.path.exists(im_b):
            pairs.append((im_a, im_b))
        else:
            print(f"Warning: æ‰¾ä¸åˆ°å¯¹åº”çš„åå¸§å›¾åƒ {im_b}ï¼Œè·³è¿‡è¯¥å¯¹ã€‚")
    return pairs
def demo(args):
    import time
    # åŠ è½½RAFTæ¨¡å‹å¹¶å¯ç”¨DataParallelï¼ˆæ”¯æŒå¤šGPUï¼‰
    model = torch.nn.DataParallel(RAFT(args))
    # åŠ è½½æ¨¡å‹æƒé‡ï¼ŒåªåŠ è½½æƒé‡éƒ¨åˆ†
    model.load_state_dict(torch.load(args.model, weights_only=True), strict=False)
    model = model.module
    model.to(DEVICE)
    model.eval()

    with torch.no_grad():
        image_pairs = get_image_pairs(args.path)

        print(f"å…±æ‰¾åˆ° {len(image_pairs)} å¯¹å›¾åƒè¿›è¡Œå¤„ç†ã€‚")
        # è‡ªåŠ¨åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        os.makedirs(args.output_path, exist_ok=True)

        total_infer_time = 0.0  # ç´¯è®¡æ¨ç†æ—¶é—´
        count = 0

        for imfile1, imfile2 in image_pairs:
            print(f"å¤„ç†å›¾åƒå¯¹: {os.path.basename(imfile1)} å’Œ {os.path.basename(imfile2)}")
            image1 = load_image(imfile1).to(DEVICE)
            image2 = load_image(imfile2).to(DEVICE)

            # å¡«å……å›¾åƒåˆ°åˆé€‚å°ºå¯¸
            padder = InputPadder(image1.shape, mode='sintel')
            image1, image2 = padder.pad(image1, image2)

            # åªç»Ÿè®¡æ¨¡å‹æ¨ç†æ—¶é—´
            start_infer = time.time()
            flow_low, flow_up = model(image1, image2, iters=12, test_mode=True)
            if torch.cuda.is_available():
                torch.cuda.synchronize()  # ä¿è¯GPUæ¨ç†å®Œæˆï¼Œè®¡æ—¶å‡†ç¡®
            end_infer = time.time()

            infer_time = (end_infer - start_infer) * 1000  # è½¬æ¢æˆæ¯«ç§’
            total_infer_time += infer_time
            count += 1
            print(f"æ¨¡å‹æ¨ç†è€—æ—¶: {infer_time:.3f} æ¯«ç§’")
            # è£å‰ªå›åŸå§‹å°ºå¯¸
            flow_up = padder.unpad(flow_up)

            # å®šä¹‰è¾“å‡ºè·¯å¾„
            output_name = os.path.splitext(os.path.basename(imfile1))[0]
            prefix = output_name[:-2] if output_name.endswith('_a') else output_name

            flo_filename = os.path.join(args.output_path, f"flow_{prefix}.flo")
            output_path = os.path.join(args.output_path, f"flow_{prefix}.jpg")

            # ä¿å­˜å…‰æµæ–‡ä»¶
            save_flow(flo_filename, flow_up.cpu().numpy())

            # å¯è§†åŒ–å…‰æµ
            viz(image1, flow_up, output_path)

            output_name = os.path.splitext(os.path.basename(imfile1))[0]  # ä¾‹å¦‚ '0001_a'
            prefix = output_name[:-2] if output_name.endswith('_a') else output_name  # å˜æˆ '0001'

            flo_gt_path = os.path.join(args.flo_path, prefix + '.flo') if hasattr(args, 'flo_path') else os.path.join(
                args.path, prefix + '.flo')

            # åˆ¤æ–­çœŸå®å…‰æµæ˜¯å¦å­˜åœ¨
            if os.path.exists(flo_gt_path):
                flow_pred = flow_up[0].permute(1, 2, 0).cpu().numpy()
                flow_gt = read_flow(flo_gt_path)

                if flow_pred.shape == flow_gt.shape:
                    error_heatmap_path = os.path.join(args.output_path, prefix + '_heatmap.png')
                    save_error_heatmap(flow_pred, flow_gt, error_heatmap_path)
                    print(f"å·²ç”Ÿæˆè¯¯å·®çƒ­åŠ›å›¾åŠè¯¯å·®çŸ©é˜µ: {error_heatmap_path} / .npy")
                else:
                    print(f"é¢„æµ‹å…‰æµä¸çœŸå®å…‰æµå°ºå¯¸ä¸åŒ¹é… ({flow_pred.shape} vs {flow_gt.shape})ï¼Œè·³è¿‡è¯¯å·®çƒ­åŠ›å›¾ã€‚")
            else:
                print(f"æœªæ‰¾åˆ°çœŸå®å…‰æµæ–‡ä»¶ {flo_gt_path}ï¼Œè·³è¿‡è¯¯å·®çƒ­åŠ›å›¾ã€‚")

        if count > 0:
            print(f"å¹³å‡æ¨¡å‹æ¨ç†è€—æ—¶: {total_infer_time / count:.3f} æ¯«ç§’")
        else:
            print("æ²¡æœ‰å¤„ç†ä»»ä½•å›¾åƒå¯¹ã€‚")

# def demo(args):
#     # åŠ è½½RAFTæ¨¡å‹å¹¶å¯ç”¨DataParallelï¼ˆæ”¯æŒå¤šGPUï¼‰
#     model = torch.nn.DataParallel(RAFT(args))
#     # åŠ è½½æ¨¡å‹æƒé‡ï¼ŒåªåŠ è½½æƒé‡éƒ¨åˆ†
#     model.load_state_dict(torch.load(args.model, weights_only=True), strict=False)
#     model = model.module
#     model.to(DEVICE)
#     model.eval()
#
#     with torch.no_grad():
#         image_pairs = get_image_pairs(args.path)
#
#         print(f"å…±æ‰¾åˆ° {len(image_pairs)} å¯¹å›¾åƒè¿›è¡Œå¤„ç†ã€‚")
#         # è‡ªåŠ¨åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
#         os.makedirs(args.output_path, exist_ok=True)
#         total_time = 0.0  # ç´¯è®¡æ—¶é—´
#         count = 0
#         for imfile1, imfile2 in image_pairs:
#             import time
#             start_time = time.time()  # å¼€å§‹è®¡æ—¶
#             print(f"å¤„ç†å›¾åƒå¯¹: {os.path.basename(imfile1)} å’Œ {os.path.basename(imfile2)}")
#             image1 = load_image(imfile1).to(DEVICE)
#             image2 = load_image(imfile2).to(DEVICE)
#
#             # å¡«å……å›¾åƒåˆ°åˆé€‚å°ºå¯¸
#             padder = InputPadder(image1.shape, mode='sintel')
#             image1, image2 = padder.pad(image1, image2)
#
#             # ä½¿ç”¨RAFTæ¨¡å‹è®¡ç®—å…‰æµ
#             flow_low, flow_up = model(image1, image2, iters=12, test_mode=True)
#
#             # è£å‰ªå›åŸå§‹å°ºå¯¸
#             flow_up = padder.unpad(flow_up)
#
#             # å®šä¹‰è¾“å‡ºè·¯å¾„
#             output_path = os.path.join(args.output_path, f"flow_{os.path.splitext(os.path.basename(imfile1))[0]}.png")
#             flo_filename = os.path.splitext(output_path)[0] + '.flo'
#
#             # ä¿å­˜å…‰æµæ–‡ä»¶
#             save_flow(flo_filename, flow_up.cpu().numpy())
#
#             # å¯è§†åŒ–å…‰æµ
#             viz(image1, flow_up, output_path)
#             output_name = os.path.splitext(os.path.basename(imfile1))[0]  # ä¾‹å¦‚ '0001_a'
#             prefix = output_name[:-2] if output_name.endswith('_a') else output_name  # å˜æˆ '0001'
#
#             flo_gt_path = os.path.join(args.flo_path, prefix + '.flo') if hasattr(args, 'flo_path') else os.path.join(
#                 args.path, prefix + '.flo')
#
#             # åˆ¤æ–­çœŸå®å…‰æµæ˜¯å¦å­˜åœ¨
#             if os.path.exists(flo_gt_path):
#                 # è½¬æ¢é¢„æµ‹å…‰æµä¸º numpy æ ¼å¼
#                 flow_pred = flow_up[0].permute(1, 2, 0).cpu().numpy()
#                 flow_gt = read_flow(flo_gt_path)
#
#                 if flow_pred.shape == flow_gt.shape:
#                     # æ„é€ è¯¯å·®çƒ­åŠ›å›¾ä¿å­˜è·¯å¾„
#                     error_heatmap_path = os.path.join(args.output_path, prefix + '_heatmap.png')
#
#                     # ä¿å­˜è¯¯å·®çƒ­åŠ›å›¾ + åŒå .npy æ–‡ä»¶
#                     save_error_heatmap(flow_pred, flow_gt, error_heatmap_path)
#                     print(f"å·²ç”Ÿæˆè¯¯å·®çƒ­åŠ›å›¾åŠè¯¯å·®çŸ©é˜µ: {error_heatmap_path} / .npy")
#                 else:
#                     print(f"é¢„æµ‹å…‰æµä¸çœŸå®å…‰æµå°ºå¯¸ä¸åŒ¹é… ({flow_pred.shape} vs {flow_gt.shape})ï¼Œè·³è¿‡è¯¯å·®çƒ­åŠ›å›¾ã€‚")
#             else:
#                 print(f"æœªæ‰¾åˆ°çœŸå®å…‰æµæ–‡ä»¶ {flo_gt_path}ï¼Œè·³è¿‡è¯¯å·®çƒ­åŠ›å›¾ã€‚")
#                 end_time = time.time()  # ç»“æŸè®¡æ—¶
#                 elapsed = end_time - start_time
#                 total_time += elapsed
#                 count += 1
#                 print(f"è¯¥å¯¹å›¾åƒå¤„ç†è€—æ—¶: {elapsed:.3f} ç§’")
#
#             if count > 0:
#                 print(f"å¹³å‡æ¯å¯¹å›¾åƒå¤„ç†è€—æ—¶: {total_time / count:.3f} ç§’")
#             else:
#                 print("æ²¡æœ‰å¤„ç†ä»»ä½•å›¾åƒå¯¹ã€‚")
if __name__ == '__main__':
    # è®¾ç½®å‘½ä»¤è¡Œå‚æ•°è§£æ
    parser = argparse.ArgumentParser()
    parser.add_argument('--model',default='checkpoints/250000_raft-river.pth', help="restore checkpoint")  # æ¨¡å‹æƒé‡è·¯å¾„250000_raft-river.pth
    parser.add_argument('--path',default='E:/test_data/test_river/UAV/test_V',help="dataset for evaluation")  # æ•°æ®é›†è·¯å¾„ 'Tracer', 'Turbulent'
    parser.add_argument('--small', action='store_true', help='use small model')  # æ˜¯å¦ä½¿ç”¨å°æ¨¡å‹
    parser.add_argument('--mixed_precision', action='store_true', help='use mixed precision')  # æ˜¯å¦ä½¿ç”¨æ··åˆç²¾åº¦
    parser.add_argument('--alternate_corr', action='store_true',
                        help='use efficient correlation implementation')  # æ˜¯å¦ä½¿ç”¨é«˜æ•ˆç›¸å…³æ€§å®ç°
    parser.add_argument('--output_path',default='E:/test_data/test_river/UAV/3/RAFT', help="#COVNEXT;output path to save optical flow images")  # è¾“å‡ºè·¯å¾„
    parser.add_argument('--use_basic_layer', action='store_true', default=False, help='Whether to use the basic layer')
    args = parser.parse_args()  # è§£æå‘½ä»¤è¡Œå‚æ•°

   # demo(args)  # è°ƒç”¨å•æ–‡ä»¶ï¼šä¸»å‡½æ•°
    # è·å– path ä¸‹æ‰€æœ‰å­æ–‡ä»¶å¤¹
    subfolders = [f for f in os.listdir(args.path) if os.path.isdir(os.path.join(args.path, f))]

    if not subfolders:
        # å¦‚æœæ²¡æœ‰å­æ–‡ä»¶å¤¹ï¼Œç›´æ¥è¿è¡Œä¸€æ¬¡ demo
        print(f"ğŸ“‚ è¾“å…¥è·¯å¾„ä¸‹æ— å­æ–‡ä»¶å¤¹ï¼Œç›´æ¥è¿è¡Œå•æ¬¡å¤„ç†: {args.path}")
        demo(args)
    else:
        print(f"ğŸ” å‘ç°å¤šä¸ªå­æ–‡ä»¶å¤¹ï¼Œä¾æ¬¡å¤„ç†: {subfolders}")
        for sub in subfolders:
            # æ„é€ æ¯ä¸ªå­æ–‡ä»¶å¤¹å¯¹åº”çš„è¾“å…¥è¾“å‡ºè·¯å¾„
            sub_input_path = os.path.join(args.path, sub)
            sub_output_path = os.path.join(args.output_path, sub)

            # åˆ›å»ºæ–°çš„ args å®ä¾‹ï¼Œå¤åˆ¶åŸå‚æ•°ï¼Œä½†ä¿®æ”¹ path å’Œ output_path
            sub_args = argparse.Namespace(
                model=args.model,
                path=sub_input_path,
                small=args.small,
                mixed_precision=args.mixed_precision,
                alternate_corr=args.alternate_corr,
                output_path=sub_output_path,
                use_basic_layer=args.use_basic_layer
            )

            print(f"\nğŸš€ æ­£åœ¨å¤„ç†ï¼š{sub_input_path}")
            demo(sub_args)

